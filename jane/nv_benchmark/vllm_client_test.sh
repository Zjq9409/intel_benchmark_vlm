python3 ../../vllm_benchmark/benchmark_serving.py \
  --backend openai-chat \
  --model /disk0/LLM/Qwen2-VL-72B-Instruct/ \
  --endpoint /v1/chat/completions \
  --dataset-name hf \
  --hf-split train \
  --num-prompts 1 \
  --max-concurrency 1 \
  --port 8000 \
  --host 127.0.0.1 \
  --seed 0 \
  --hf-output-len 128 \
  --ignore-eos  \
  --dataset-path /root/jane/VisionArena-Chat \
