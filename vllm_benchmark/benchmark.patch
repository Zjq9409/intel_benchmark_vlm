diff --git a/benchmarks/backend_request_func.py b/benchmarks/backend_request_func.py
index 800d426c6..2733ffb1b 100644
--- a/benchmarks/backend_request_func.py
+++ b/benchmarks/backend_request_func.py
@@ -45,6 +45,7 @@ class RequestFuncOutput:
     itl: list[float] = field(default_factory=list)  # list of inter-token latencies
     tpot: float = 0.0  # avg next-token latencies
     prompt_len: int = 0
+    image_prompt_total_len: int = 0
     error: str = ""
 
 
@@ -416,6 +417,7 @@ async def async_request_openai_chat_completions(
                                 generated_text += content or ""
                             elif usage := data.get("usage"):
                                 output.output_tokens = usage.get("completion_tokens")
+                                output.image_prompt_total_len = usage.get("prompt_tokens")
 
                             most_recent_timestamp = timestamp
 
diff --git a/benchmarks/benchmark_dataset.py b/benchmarks/benchmark_dataset.py
index d8f48644c..cd62d576b 100644
--- a/benchmarks/benchmark_dataset.py
+++ b/benchmarks/benchmark_dataset.py
@@ -256,6 +256,7 @@ def process_image(image: Any) -> Mapping[str, Any]:
     """
     if isinstance(image, dict) and "bytes" in image:
         image = Image.open(BytesIO(image["bytes"]))
+        print("image size: ", image.size)
     if isinstance(image, Image.Image):
         image = image.convert("RGB")
         with io.BytesIO() as image_data:
@@ -719,7 +720,8 @@ class VisionArenaDataset(HuggingFaceDataset):
         for item in self.data:
             if len(sampled_requests) >= num_requests:
                 break
-            parser_fn = self.SUPPORTED_DATASET_PATHS.get(self.dataset_path)
+            # parser_fn = self.SUPPORTED_DATASET_PATHS.get(self.dataset_path)
+            parser_fn = self.SUPPORTED_DATASET_PATHS.get("lmarena-ai/VisionArena-Chat")
             if parser_fn is None:
                 raise ValueError(f"Unsupported dataset path: {self.dataset_path}")
             prompt = parser_fn(item)
diff --git a/benchmarks/benchmark_serving.py b/benchmarks/benchmark_serving.py
index a887e7150..12e2cde3e 100644
--- a/benchmarks/benchmark_serving.py
+++ b/benchmarks/benchmark_serving.py
@@ -79,6 +79,7 @@ MILLISECONDS_TO_SECONDS_CONVERSION = 1000
 class BenchmarkMetrics:
     completed: int
     total_input: int
+    image_prompt_input_lens: int
     total_output: int
     request_throughput: float
     request_goodput: float
@@ -161,6 +162,7 @@ def calculate_metrics(
 ) -> tuple[BenchmarkMetrics, list[int]]:
     actual_output_lens: list[int] = []
     total_input = 0
+    image_prompt_input_lens = 0
     completed = 0
     good_completed = 0
     itls: list[float] = []
@@ -186,6 +188,7 @@ def calculate_metrics(
             actual_output_lens.append(output_len)
             total_input += input_requests[i].prompt_len
             tpot = 0
+            image_prompt_input_lens += outputs[i].image_prompt_total_len
             if output_len > 1:
                 latency_minus_ttft = outputs[i].latency - outputs[i].ttft
                 tpot = latency_minus_ttft / (output_len - 1)
@@ -233,6 +236,7 @@ def calculate_metrics(
     metrics = BenchmarkMetrics(
         completed=completed,
         total_input=total_input,
+        image_prompt_input_lens=image_prompt_input_lens,
         total_output=sum(actual_output_lens),
         request_throughput=completed / dur_s,
         request_goodput=good_completed / dur_s,
@@ -346,6 +350,7 @@ async def benchmark(
             extra_body=extra_body,
         )
         profile_output = await request_func(request_func_input=profile_input)
+        print(profile_output)
         if profile_output.success:
             print("Profiler started")
 
@@ -435,6 +440,7 @@ async def benchmark(
     print("{:<40} {:<10}".format("Successful requests:", metrics.completed))
     print("{:<40} {:<10.2f}".format("Benchmark duration (s):", benchmark_duration))
     print("{:<40} {:<10}".format("Total input tokens:", metrics.total_input))
+    print("{:<40} {:<10}".format("Total image and input tokens:", metrics.image_prompt_input_lens))
     print("{:<40} {:<10}".format("Total generated tokens:", metrics.total_output))
     print(
         "{:<40} {:<10.2f}".format(
@@ -462,6 +468,7 @@ async def benchmark(
         "duration": benchmark_duration,
         "completed": metrics.completed,
         "total_input_tokens": metrics.total_input,
+        "total_prompt_image_input_tokens": metrics.image_prompt_input_lens,
         "total_output_tokens": metrics.total_output,
         "request_throughput": metrics.request_throughput,
         "request_goodput:": metrics.request_goodput if goodput_config_dict else None,
@@ -655,42 +662,45 @@ def main(args: argparse.Namespace):
     elif args.dataset_name == "hf":
         # all following datasets are implemented from the
         # HuggingFaceDataset base class
-        if args.dataset_path in VisionArenaDataset.SUPPORTED_DATASET_PATHS:
-            dataset_class = VisionArenaDataset
-            args.hf_split = "train"
-            args.hf_subset = None
-        elif args.dataset_path in InstructCoderDataset.SUPPORTED_DATASET_PATHS:
-            dataset_class = InstructCoderDataset
-            args.hf_split = "train"
-        elif args.dataset_path in MTBenchDataset.SUPPORTED_DATASET_PATHS:
-            dataset_class = MTBenchDataset
-            args.hf_split = "train"
-        elif args.dataset_path in ConversationDataset.SUPPORTED_DATASET_PATHS:
-            dataset_class = ConversationDataset
-        elif args.dataset_path in AIMODataset.SUPPORTED_DATASET_PATHS:
-            dataset_class = AIMODataset
-            args.hf_split = "train"
-        elif args.dataset_path in NextEditPredictionDataset.SUPPORTED_DATASET_PATHS:  # noqa: E501
-            dataset_class = NextEditPredictionDataset
-            args.hf_split = "train"
-        elif args.dataset_path in ASRDataset.SUPPORTED_DATASET_PATHS:
-            dataset_class = ASRDataset
-            args.hf_split = "train"
-        else:
-            supported_datasets = set(
-                [
-                    dataset_name
-                    for cls in HuggingFaceDataset.__subclasses__()
-                    for dataset_name in cls.SUPPORTED_DATASET_PATHS
-                ]
-            )
-            raise ValueError(
-                f"Unsupported dataset path: {args.dataset_path}. "
-                "Huggingface dataset only supports dataset_path"
-                f" from one of following: {supported_datasets}. "
-                "Please consider contributing if you would "
-                "like to add support for additional dataset formats."
-            )
+        dataset_class = VisionArenaDataset
+        args.hf_split = "train"
+        args.hf_subset = None
+        # if args.dataset_path in VisionArenaDataset.SUPPORTED_DATASET_PATHS:
+        #     dataset_class = VisionArenaDataset
+        #     args.hf_split = "train"
+        #     args.hf_subset = None
+        # elif args.dataset_path in InstructCoderDataset.SUPPORTED_DATASET_PATHS:
+        #     dataset_class = InstructCoderDataset
+        #     args.hf_split = "train"
+        # elif args.dataset_path in MTBenchDataset.SUPPORTED_DATASET_PATHS:
+        #     dataset_class = MTBenchDataset
+        #     args.hf_split = "train"
+        # elif args.dataset_path in ConversationDataset.SUPPORTED_DATASET_PATHS:
+        #     dataset_class = ConversationDataset
+        # elif args.dataset_path in AIMODataset.SUPPORTED_DATASET_PATHS:
+        #     dataset_class = AIMODataset
+        #     args.hf_split = "train"
+        # elif args.dataset_path in NextEditPredictionDataset.SUPPORTED_DATASET_PATHS:  # noqa: E501
+        #     dataset_class = NextEditPredictionDataset
+        #     args.hf_split = "train"
+        # elif args.dataset_path in ASRDataset.SUPPORTED_DATASET_PATHS:
+        #     dataset_class = ASRDataset
+        #     args.hf_split = "train"
+        # else:
+        #     supported_datasets = set(
+        #         [
+        #             dataset_name
+        #             for cls in HuggingFaceDataset.__subclasses__()
+        #             for dataset_name in cls.SUPPORTED_DATASET_PATHS
+        #         ]
+        #     )
+        #     raise ValueError(
+        #         f"Unsupported dataset path: {args.dataset_path}. "
+        #         "Huggingface dataset only supports dataset_path"
+        #         f" from one of following: {supported_datasets}. "
+        #         "Please consider contributing if you would "
+        #         "like to add support for additional dataset formats."
+        #     )
 
         if dataset_class.IS_MULTIMODAL and backend not in [
             "openai-chat",
